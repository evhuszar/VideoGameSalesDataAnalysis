```{r}
#load libraries
suppressMessages(library(rpart)) 
suppressMessages(library(rattle))
suppressMessages(library(rpart.plot))
suppressMessages(library(caret))
suppressMessages(library(forcats))
suppressMessages(library(dplyr))
suppressMessages(library(randomForest))
suppressMessages(library(lattice))
suppressMessages(library(naniar))
suppressMessages(library(caret))
suppressMessages(library(glmnet))
```

# Elastic Net

```{r}

#Set a random seed
set.seed(27)

Xlm = vgData
Xlm$year2 = (X$Year)^2

#Create the model matrix
XD <- model.matrix(Global_Sales ~ ., data = Xlm)
XD = data.frame(XD)
XD = XD
XD$Global_Sales =vgData$Global_Sales

#Values of alpha and lambda to test
tuningGrid <- data.frame("alpha" = seq(from = 0, to = 1, by = .05), "lambda"= seq(from =0, to =5, by =.25))

set.seed(27)

#Preform cross validation for elastic net
globalSales_elnet = train(
  Global_Sales ~ ., data = XD,
  method = "glmnet",
  tuneGrid = tuningGrid,
  trControl = trainControl(method = "cv", number = 10)
)

#Find the lowest RMSE
location = which(globalSales_elnet$results$RMSE==min(globalSales_elnet$results$RMSE))
ElasticRMSE = globalSales_elnet$results[location,3] 
suppressMessages(knitr::kable(round(globalSales_elnet$results[location,1:3],2),caption = "Tuning Parameters for Best Test RMSE"))
```

Table 6 shows the results of cross validation with the different values of $\lambda$ and $\alpha$. The values that are shown are the values that gave the lowest test RMSE. Since $\lambda$ = 0 was chosen this means the most is the same as a least square linear regression since now to get the coefficients it is only minimizing RSS without any penalty. The test RMSE calculated from 10 fold cross validation is 1.94, so the predictions ar about 1,940,000 sales off on average.

```{r}
#Create the elastic net model with lambda 0 and alpha=0 and find the coefficients
ridgeFinal <- glmnet(XD[,-c(1,90)],XD$Global_Sales,alpha=0,lambda=0)
Betas <- as.numeric(coef(ridgeFinal))
rowNames <- colnames(XD[,-90])
BetasFinal <- data.frame("Column Names" = rowNames, "Coefficients" = round(Betas,2))
knitr::kable(BetasFinal[order(BetasFinal$Coefficients),],
    caption = "Elastic Net Features and Coefficients")
```
Table 7 above shows the coefficients for the model.  The model uses all features, except one, so there are 88 $\hat{\beta}$ values in all. The only feature that was removed from the model is ESRB Rating KA, since it has a coefficient of 0, the other coefficients that were close to zero like for $Year^2$ were rounded up. The KA rating also had negative important in the Random Forest. The features with the largest positive coefficients, besides the intercept are the platforms And and Xbox One, publisher Nintendo, critic score high, and genre MMO. This is similar to the results from the first and second model. The forest in model 1 found the platform And was not important, but with elastic net it shows that the platform And leads to a higher global sales by about 1,519,000 sales. Nintendo increases the sales by 1,490,138. The features that lead to a lower Global Sales are any publisher that is not EA sports or Nintendo, in fact 11 out of the 16 platforms have 11 out of 12 the most negative coefficients. The coefficients for these platforms are between -0.86 and -0.43. Therefore if the video game was published by one of these 11 publishers the predicted global sales decrease anywhere from 452,561 to 860,876. Platform DSIW also has a negative coefficient of 0.85. The feature Year, which was used in the forest and LSLR has a coefficient of -0.01 and -0.0000000031 for $Year^2$. Since the earliest year is 1970 these small coefficients still have an affect on global sales. So again the newer the game the lower the predicted global sales.  Interestingly, the missing critic scores have a positive coefficient in this model of 0.013, the only critic score that does not increase the predicted global sales is an average score. 
