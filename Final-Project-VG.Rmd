---
title: "Final Project"
author: "Evelyn Huszar"
date: "5/3/2022"
output:
  pdf_document: default
  toc: true
  number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r}
#load libraries
suppressMessages(library(rpart)) 
suppressMessages(library(rattle))
suppressMessages(library(rpart.plot))
suppressMessages(library(caret))
suppressMessages(library(forcats))
suppressMessages(library(dplyr))
suppressMessages(library(randomForest))
suppressMessages(library(lattice))
suppressMessages(library(naniar))
```

\newpage

\tableofcontents
\newpage

# Abstract

In this report we will discuss the process of predicting the global sales for different video games released since 1970.  This will be done by utilizing different regression models with varying amounts of features then comparing their results. We will identify key features of a video game that are associated with global sales and explain how these features impact the sales of the video game. After cleaning the data and using imputation to add missing features four models that will be created to predict global sales. The model that will used are Regression Trees, Random Forests, Elastic Net, and Least Squares Linear Regression. Each step of the process will be explained for four models for prediction and association. The best model will be Least Squares Linear Regression with a test root mean square error of 0.62 and 6 features. This means for the model the predictions were off by 620,000 sales. The worst model is the regression tree which gets a score of 2.03, so a random forest is used instead. The random forest has a test root mean square error of 1.84 then lastly Elastic Net has 1.94. The features for all four models that lead to the highest predicted global sales were the publisher Nintendo and games that had a higher critic and user score. The features that lead to a lower predicted global sales were the year the game was released. 


# Section 1: Data and Motivation

The data contains a list of video games and the total worldwide sales per 1,000,000 copies. The data set was created from information from vgchartz.com which is a database that contains information on over 55,000 video games. The original data set has 55,792 rows and 16 columns.[2] It has the statistics for the platforms and developers of the video games. The website allows it's critics and millions of users to update information on the video games, leave reviews, and give a rating score for the video game. The rating scores for the video games are between 0 and 10. It contains data from video games as early as 1970 to as recent as 2020. Therefore the features that were included in the data set are year released, release platforms, developer, ESRB rating, publisher, critic score, user score, sales in North America, sales in Japan, other sales, and total shipped. ESRB Rating is the content rating for the video game, there are 9 different ratings in the data set such as E for everyone, E10 for everyone 10 and up, M for mature, etc. There are 74 different platforms the games have been released on, 8065 different developers, and 2065 different publishers. The sales rows and total shipped are numeric features that also measure how many video games were shipped or sold out of 1,000,000 copies. 

Given the data we will be exploring how well the features predict global sales. Since global sales are by 1,000,000 copies the response variable is numeric. Once models are created we will also see which features can best be used to predict global sales and which features lead to higher global sales. The tasks will be prediction and association. We want to know which video games tend to sell better.

# Section 2: Data Cleaning and EDA

```{r}
#load the data
vgSales<- read.csv("C:/Users/papri/Downloads/vgsales-12-4-2019-short.csv/vgsales-12-4-2019-short.csv")
```

```{r}
#Combining factors together to reduce number of factors.
convertTooSmall <- function(x){
  columnHere <- x
  holder <- as.data.frame(table(columnHere))
  holderperc <- holder$Freq/sum(holder$Freq)
  #find which categories appear in less than 10% of the data
  tooSmall <- which(holderperc < .01)
  choices <- levels(columnHere)
  table(columnHere)
  #Find categories that do not show up often
  levels(columnHere) <- c(levels(columnHere), "Other")
  #Combine the categories into other
  columnHere[columnHere %in% choices[tooSmall]] <- "Other"
  columnHere <- factor(columnHere)
  columnHere
}
```

The starting data set has 55,792 rows, however many video games are listed multiple times as they can be released on multiple platforms. To start off for cleaning the data we will look at the 74 different platforms which are listed below.

```{r}
#show the rows of the column platform
vgSales$Platform = as.factor(vgSales$Platform)
knitr::kable(table(vgSales$Platform), caption = "Platforms")
```
Table 1 shows platforms like "Aco", "BBCM", "C128", only have one video game listed as released on it. This may because the platform "C128" is one of the first ever gaming platforms and does not have many games on it so a lot of users may have not used some of the platforms listed. To consolidate some of the platforms they will be combined into one column "other". Since most of the video games are the platform PC, we will only keep the platforms that there are more than 600 games on the platform the rest will be combined into 'other'. 

```{r}
#Combining platform levels into other
vgSales$Platform <- convertTooSmall(vgSales$Platform)
knitr::kable(table(vgSales$Platform), caption = "Platforms Combined")
```

Now Table 2 shows there are only 29 different platforms. The same will be done to the column publisher and developer. There are 8065 different developers and 3069 different publishers. Instead of combining columns that only have less than 600 rows, columns that have less than 100 rows of data will be combined. Now there are 14 different developers and 16 publishers.

In order to remove video games that are listed more than once the rows with the same video game will be combined. The publisher, year, and developer will which ever year, developer, and publisher came first since games can have multiple release years, publishers, and developers. The 29 platform levels will each be turned into a Boolean column, 1 if the video game was released on that platform and 0 if not. Critic Scores and User Scores for the game will be averaged to get the mean score the game was given. Finally the feature for global sales and total shipped will be adding together for each game. The columns for NA sales, Japan sales, and other sales will be removed since they are correlated to global sales and total shipped. 

```{r}
#Combining factors together to reduce number of factors.
# Combing developers and publishers twice to reduce levels
vgSales$Publisher <- convertTooSmall(vgSales$Publisher)
vgSales$Publisher <- convertTooSmall(vgSales$Publisher)
```

```{r}
#Combining factors together to reduce number of factors.
convertTooSmall <- function(x){
  columnHere <- x
  holder <- as.data.frame(table(columnHere))
  holderperc <- holder$Freq/sum(holder$Freq)
  #find which categories appear in less than 10% of the data
  tooSmall <- which(holderperc < .005)
  choices <- levels(columnHere)
  table(columnHere)
  #Find categories that do not show up often
  levels(columnHere) <- c(levels(columnHere), "Other")
  #Combine the categories into other
  columnHere[columnHere %in% choices[tooSmall]] <- "Other"
  columnHere <- factor(columnHere)
  columnHere
}

vgSales$Developer <- convertTooSmall(vgSales$Developer)
vgSales$Developer <- convertTooSmall(vgSales$Developer)
vgSales$Developer <- convertTooSmall(vgSales$Developer)
```

```{r}
#Create a new data frame with the same titles combined

#save the unique titles
#vg_titles = unique(vgSales$Name)

#find unique platform
#platforms = unique(vgSales$Platform)

#length of new data frame
#tt = length(vg_titles)

#vgData = data.frame("Name" = rep(NA,tt),"Year" = rep(NA,tt),"Genre" = rep(NA,tt), "Platform_3DS" = rep(0,tt),"Platform_And" = rep(0,tt),"Platform_DC" = rep(0,tt),"Platform_DS" = rep(0,tt), "Platform_DSIW" = rep(0,tt), "Platform_GB" =rep(0,tt),  "Platform_GBA" = rep(0,tt), "Platform_GC" = rep(0,tt), "Platform_GEN" = rep(0,tt),"Platform_NES" = rep(0,tt), "Platform_NS" = rep(0,tt),"Platform_OSX"=rep(0,tt),"Platform_PC" = rep(0,tt), "Platform_PS" = rep(0,tt),"Platform_PS2"=rep(0,tt),"Platform_PS3"=rep(0,tt), "Platform_PS4"=rep(0,tt),"Platform_PSN" = rep(0,tt),"Platform_PSP" = rep(0,tt),"Platform_PSV" = rep(0,tt), "Platform_SAT"=rep(0,tt), "Platform_SNES" = rep(0,tt), "Platform_VC" = rep(0,tt), "Platform_Wii" = rep(0,tt), "Platform_X360"=rep(0,tt), "Platform_XB" = rep(0,tt), "Platform_XBL" = rep(0,tt), "Platform_XOne" = rep(0,tt), "Platform_Other" = rep(0,tt), "ESRB_Rating" = rep(NA,tt),"Publisher" =rep(NA,tt),"Developer"=rep(NA,tt),"Critic_Score"=rep(NA,tt),"User_Score"=rep(NA,tt),"Total_Shipped"=rep(NA,tt),"Global_Sales"=rep(NA,tt))

#loop through all titles
#i = 1  #keep track of what row
#for (name in vg_titles){
#  #find the rows with that videogame title
#  location = which(vgSales$Name == name)
  
  #save the name, first year, first ESRB Rating, Publisher, developer, and genre listed for the specific videogame
#  vgData$Name[i] = name
#  vgData$Year[i] = unique(vgSales$Year[location])[1]
#  vgData$ESRB_Rating[i] =unique(vgSales$ESRB_Rating[location])[1]
#  vgData$Publisher[i]= as.character(unique(vgSales$Publisher[location])[1])
#  vgData$Developer[i] = as.character(unique(vgSales$Developer[location])[1])
#  vgData$Genre[i] = as.character(unique(vgSales$Genre[location])[1])
  
  #find all unique platforms for the title
#  gameplat_forms = unique(vgSales$Platform[location])
  
  #save a 1 if th platform is in the list
#  if ("3DS" %in% gameplat_forms){
#    vgData$Platform_3DS[i] = 1
#  }
  
#  if ("And" %in% gameplat_forms){
#    vgData$Platform_And[i] = 1
#  }
  
#  if ("DC" %in% gameplat_forms){
#    vgData$Platform_DC[i] = 1
#  }
#  if ("DS" %in% gameplat_forms){
#    vgData$Platform_DS[i] = 1
#  }
  
#  if ("DSiW" %in% gameplat_forms){
#    vgData$Platform_DSIW[i] = 1
#  }
  
#  if ("GB" %in% gameplat_forms){
#    vgData$Platform_GB[i] = 1
#  }
#  if ("GBA" %in% gameplat_forms){
#    vgData$Platform_GBA[i] = 1
#  }
#  if ("GC" %in% gameplat_forms){
#    vgData$Platform_GC[i] = 1
#  }
#  if ("GEN" %in% gameplat_forms){
#    vgData$Platform_GEN[i] = 1
#  }
  
#  if ("NES" %in% gameplat_forms){
#    vgData$Platform_NES[i] = 1
#  }
#  if ("NS" %in% gameplat_forms){
#    vgData$Platform_NS[i] = 1
#  }
#  if ("OSX" %in% gameplat_forms){
#    vgData$Platform_OSX[i] = 1
#  }
#  if ("PC" %in% gameplat_forms){
#    vgData$Platform_PC[i] = 1
#  }
  
#  if ("PS" %in% gameplat_forms){
#    vgData$Platform_PS[i] = 1
#  }
#  if ("PS2" %in% gameplat_forms){
#    vgData$Platform_PS2[i] = 1
#  }
#  if ("PS3" %in% gameplat_forms){
#    vgData$Platform_PS3[i] = 1
#  }  
#  if ("PS4" %in% gameplat_forms){
#    vgData$Platform_PS4[i] = 1
#  }
  
#  if ("PSN" %in% gameplat_forms){
#    vgData$Platform_PSN[i] = 1
#  }
#  if ("PSP" %in% gameplat_forms){
#    vgData$Platform_PSP[i] = 1
#  }
#  if ("PSV" %in% gameplat_forms){
#    vgData$Platform_PSV[i] = 1
#  }
#  if ("SAT" %in% gameplat_forms){
#    vgData$Platform_SAT[i] = 1
#  }
  
#  if ("SNES" %in% gameplat_forms){
#    vgData$Platform_SNES[i] = 1
#  }
#  if ("VC" %in% gameplat_forms){
#    vgData$Platform_VC[i] = 1
#  }
#  if ("Wii" %in% gameplat_forms){
#    vgData$Platform_Wii[i] = 1
#  }
#  if ("X360" %in% gameplat_forms){
#    vgData$Platform_X360[i] = 1
#  }

#  if ("XB" %in% gameplat_forms){
#    vgData$Platform_XB[i] = 1
#  }
#  if ("XBL" %in% gameplat_forms){
#    vgData$Platform_XBL[i] = 1
#  }
#  if ("XOne" %in% gameplat_forms){
#    vgData$Platform_XOne[i] = 1
#  }  
#  if ("Other" %in% gameplat_forms){
#    vgData$Platform_Other[i] = 1
#  }
  
  
  #take mean of critic score and user score
#  vgData$Critic_Score[i] = mean(na.omit(unique(vgSales$Critic_Score[location])))
#  vgData$User_Score[i] = mean(na.omit(unique(vgSales$User_Score[location])))
  
  #sum the total shipped and global sales
#  vgData$Total_Shipped[i] = sum(na.omit(unique(vgSales$Total_Shipped[location])))
#  vgData$Global_Sales[i] = sum(na.omit(unique(vgSales$Global_Sales[location])))
  
  #chance 0 total shipped and global sales to NA
#  zeros = which(vgData$Total_Shipped == 0)
#  vgData$Total_Shipped[zeros] = NA
#  globalZero = which(vgData$Global_Sales == 0)
#  vgData$Global_Sales[globalZero] = NA

  #Change missing ESRB to NA
#  ESRBzeros = which(vgData$ESRB_Rating == "")
#  vgData$ESRB_Rating[ESRBzeros] = NA
#  i = i+1
#}

```


The new data set now was 37,102 rows, meaning there were 37,102 unique video games in the original data set with 16 columns. Now the titles of the video games can be removed and put aside as they are unique for each row and cannot be used for the models. Next before making the model we will also look at any data that is still missing.

```{r}
#Save the new data set and comment out the for loop
#write.csv(vgData, "vgData.csv",row.names = FALSE) 
```

```{r}
#load new cleaned data set
vgData <- read.csv("~/Statistical Learning/vgData.csv")
```

```{r}
#Show any values that are still missing
suppressMessages(vis_miss(vgData[,c(2,3,33,34,35,36,37,38,39)]))+ labs(title = "Figure 2.1:")
```
Figure 2.1 shows the missing rows of all columns other than the 29 columns that correspond to platforms and the titles of the video games. Since the data is updated by users, a lot of information is still missing. Global sales are still missing 66.5% of it's data, however many of the missing rows are listed instead in total shipped.  Since they measure similar metrics any missing values in global sales will be filled with the values in total shipped. The same will be done with critic score and user score to get one column for critic score, however if any rows have both a critic score and user score then the average will be used. Only one percent of the column Year is missing so those rows will be removed. Afterwards any rows that still are missing global sales will be removed and set aside to use later to compare the models.

```{r}
#Replace global sales with total shipped if global sales are missing and total shipped is not
no_sales = which(is.na(vgData$Global_Sales))

#Replace the missing global sales with the total shipped
vgData$Global_Sales[no_sales] = vgData$Total_Shipped[no_sales]

#Take the larger of the two values as the global sales
larger = which(vgData$Global_Sales < vgData$Total_Shipped)
vgData$Global_Sales[larger] = vgData$Total_Shipped[larger]

#Combing user score and critic score
yes_user_score = which(is.na(vgData$User_Score) == FALSE)

for (r in yes_user_score){
  if (is.na(vgData$Critic_Score[r])){
    vgData$Critic_Score[r] = vgData$User_Score[r]
  } else {
  vgData$Critic_Score[r] = mean(vgData$Critic_Score[r], vgData$User_Score[r])
  }
}



vgData = vgData[,-c(37,38)]
```


```{r}
#chance categorical columns into factors and numeric into numeric
withZerosData = vgData
for (i in 3:35){
  vgData[,i] = as.factor(vgData[,i])
}
vgData[,2] = as.numeric(vgData[,2])


#find the missing global sales and save two data frames, one with the missing sales and one without
zeros = which(is.na(vgData$Global_Sales))

vgTest = vgData[zeros,]
vgData = vgData[-zeros,]

#Remove the missing years from the test data and training data
zeros2 = which(is.na(vgData$Year))
zeros3 = which(is.na(vgTest$Year))
vgData= vgData[-zeros2,]
vgTest = vgTest[-zeros3,]
```


After removing missing global sales about 40% of the data was removed. To make sure that a large representation of the data was not removed or relationships were not greatly changed from the data we will compare the bar plots of the original data to the data with the rows removed.

```{r, fig.height = 5, fig.width = 6, fig.align = "center"}
#plot relationships between old data and new data
g1=suppressMessages(ggplot(withZerosData,aes(x=Year)) + geom_histogram(bins = 15, fill = 'pink',col = 'black') + labs(title = "Figure 2.2:",x = "Year With Missing Data", y= "Frequency"))
g2=suppressMessages(ggplot(vgData,aes(x=Year)) + geom_histogram(bins = 15, fill = 'pink',col = 'black') + labs(title = "Figure 2.3:",x = "Year with Removed Rows", y="Frequency"))
gridExtra::grid.arrange(g1,g2, ncol=2,nrow=1)
```
Figure 2.2 shows the distribution of year with all the data, while Figure 2.3 shows the distribution of year in the data with rows removed. The distribution of year is about the same even without the data. The mean of the year is a bit smaller and the standard deviation has gotten smaller, but for the most part it is still representative of the original data. The same is true for the features publisher and developer. 

```{r, fig.height = 10, fig.width = 30, fig.align = "center"}
#plot the relationship between the old and new data
g1=ggplot(withZerosData,aes(x=Genre)) + geom_bar(fill = 'pink',col = 'black') + labs(title = "Figure 2.4:",x = "Genre with Missing Data")+ theme(text = element_text(size = 20))
g2=ggplot(vgData,aes(x=Genre)) + geom_bar(fill = 'pink',col = 'black') + labs(title = "Figure 2.5:",x = "Genre with Removed Rows")+ theme(text = element_text(size = 20))
gridExtra::grid.arrange(g1,g2, ncol=1,nrow=2)
```
Figure 2.4 and Figure 2.5 show the change in Genre's distribution. Genre's distribution seems to change a bit. The most popular game genre originally was miscellaneous, after removing rows there are more action games. Since the data is still representative of the different genre's available the change is not too large. However if genre is considered in a model the results may favor a different genre for higher global sales than if the original data was used. 

```{r, fig.height = 4, fig.width = 7, fig.align = "center"}
#plot the relationship between the old and the new data
g1=ggplot(withZerosData,aes(x=Platform_PC)) + geom_bar(fill = 'pink',col = 'black') + labs(title = "Figure 2.6:",x = "Games on the PC with Missing Data")
g2=ggplot(vgData,aes(x=Platform_PC)) + geom_bar(fill = 'pink',col = 'black') + labs(title = "Figure 2.7:",x = "Games on the PC with Removed Rows")
gridExtra::grid.arrange(g1,g2, ncol=2,nrow=1)
```

For the most part the different platforms distributions generally did not change. For the platforms NS, OSX, PSN, SAT, VC, XBL, DS, GBA, PS1, PS2, PS3, Xbox 360, Xbox, and the platform other, after removing the rows the ratio is the about the same. Some have a slight decrease, but most it looks the same. The platforms GC, GB, GEN, NES, 3DS, And, DC, PS4, PSP, PSV, SNES, and Wii all have a slightly higher ratio.  The biggest change in the data is the platform PC, or personal computer. Figure 2.6 shows how many games are on the PC in the original data, and Figure 2.7 shows the distribution after the missing values are removed. In the original data set about half the games were released for the PC. After removing the rows now only about one fourth of the data has been released on the PC. This is not a good representation of the true data, however PC still is the most popular platform in the data set.

```{r, fig.height = 4, fig.width = 7, fig.align = "center"}
#plot the relationship between the old and the new data
g1=ggplot(withZerosData,aes(x=ESRB_Rating)) + geom_bar(fill = 'pink',col = 'black') + labs(title = "Figure 2.8:",x = "ESRB Rating with Missing Data")
g2=ggplot(vgData,aes(x=ESRB_Rating)) + geom_bar(fill = 'pink',col = 'black') + labs(title = "Figure 2.9:",x = "ESRB Rating with Removed Rows")
gridExtra::grid.arrange(g1,g2, ncol=2,nrow=1)
```
The last feature is ESRB Rating which had the biggest change. Figure 2.8 shows the distribution with missing data, there are 9 levels not including the missing values.  Figure 2.9 shows after the missing data is removed and there are only 7 levels. After removing the rows that did not have global sales the data no long has the level AO or KA. However the original data set only had 16 games with the rating AO and 3 games with the rating KA. Because this is less than 1% of the data losing these levels did not greatly change the data set, so they can be removed without changing the data too much. They will also need to be removed from the test data so that it can be used for prediction.



```{r}
#Show if any data is still missing
vis_miss(vgData[,c(2,3,33,34,35,36,37)])+ labs(title = "Figure 2.10:")
```
Figure 2.10 shows now the only two columns that are missing data are ESRB Rating and Critic Score. Two strategies will be used to remedy the missing data. For critic score since the data is from users it may be telling about the popularity of a game if it does not have a score. Because of this critic score will be turned into a categorical feature with levels "high" for scores above 5, "average" for scores of 5, "low" for scores below 5, and lastly "unknown" if the data is missing. For ESRB rating a model will be created to predict the values of ESRB rating that are missing.  For the column ESRB Rating, only about 37% of the data is still missing.  Because of this imputation will be used.

Imputation is estimating missing values in the original data set to complete the data. The technique that will be used to impute the ESRB Rating is called classification and regression tree imputation. This is when a tree is created using the data that is not missing to predict the missing data. Since the only data that is missing is the ESRB Rating a classification tree will be created.  A classification tree splits the data using the other features; these splits create the leaves that have the final predictions. The prediction for a tree is based off which category of ESRB Rating has the highest percent in a leaf. There are seven levels to ESRB Rating. The metric to measure how good the predictions are is the classification error rate, CER. The CER is the percent of the data that is incorrectly predicted by the tree. Instead of just creating one tree to predict the missing ESRB Ratings 100 trees will be created and the predictions will be whichever rating is predicted the most out of all the trees for each missing row. Using 100 trees instead of just 1 will allow the predictions to use more of the features and compare multiple predictions to get the lowest CER. The CER is computed using the data that is available for ESRB Rating and using cross validation to check the model. Cross validation involves training the 100 trees with a portion of the data and testing with the rest and repeating this 10 times for different portions of the data, so that all the data is used as test data. The final predictions for the missing data will be saved into the data set to complete the feature ESRB Rating.

```{r}
#changing critic score to categorical for the test and training data
vgData$Critic_Score = as.numeric(vgData$Critic_Score)
for (r in 1:length(vgData$Global_Sales)){
  critic_score = vgData$Critic_Score[r]
  if (is.na(critic_score)){
    vgData$Critic_Score[r] = "Unknown"
  } else if (critic_score > 5){
    vgData$Critic_Score[r] = "high"
  } else if (critic_score < 5){
    vgData$Critic_Score[r] = "low"
  } else {
    vgData$Critic_Score[r] = "average"
  }
}
vgData$Critic_Score = as.factor(vgData$Critic_Score)

vgTest$Critic_Score = as.numeric(vgTest$Critic_Score)
for (r in 1:length(vgTest$Global_Sales)){
  critic_score = vgTest$Critic_Score[r]
  if (is.na(critic_score)){
    vgTest$Critic_Score[r] = "Unknown"
  } else if (critic_score > 5){
    vgTest$Critic_Score[r] = "high"
  } else if (critic_score < 5){
    vgTest$Critic_Score[r] = "low"
  } else {
    vgTest$Critic_Score[r] = "average"
  }
}
vgTest$Critic_Score = as.factor(vgTest$Critic_Score)

```

```{r}
#imputation for ESRB Rating
library(missForest)

#Remove titles of video games
titles = vgData[,1]
vgData = vgData[,-1]
set.seed(27)

#Create a classification forest for missing data
nc_Out <- missForest(vgData, variablewise = TRUE, ntree = 100)
df=data.frame("Variable" = colnames(vgData), "Error" = nc_Out$OOBerror)

#Save predictions
vgData <-nc_Out$ximp

#show classification error rate
location = which(df$Variable == 'ESRB_Rating')
knitr::kable(df[location,], caption = "CER for ESRB Rating Imputation")
```
Table 3 above shows the results of imputation. With the 100 trees the imputation has an error rate of 0.36 this is about 10% less than if all the missing data was assigned to have a rating of E since 46% of the data has the rating E. If any of the models identify ESRB Rating as an important feature it is important to know that the data was imputed and still had a pretty high error. Since about 16% of ESRB Rating is dependent on the other features for certain regression models like a linear model, ESRB Rating will not be considered as one of the features. 


```{r}
#Do the same imputation for the test data

#Save the titles
titlesTest = vgTest[,1]
vgTest= vgTest[,-1]

#Remove global sales since they are all missing
vgTestNoGS = vgTest[,-36]
vgGS = vgTest[,36]
set.seed(27)

#Create the forest for the test data and save the values
nc_Out <- missForest(vgTestNoGS, variablewise = TRUE, ntree = 100)
vgTest <-nc_Out$ximp
vgTest$Global_Sales= vgGS
```

Now that the data has been processed before creating regression models the relationship between variables and global sales will be explored to see if any features need transformations or if they should not be considered in the model.

```{r, fig.height = 3, fig.width = 5, fig.align = "center"}
suppressMessages(library(ggplot2))
suppressMessages(library(knitr))


#Create a boxplot of the response variable, sale price, to identify outliers
ggplot(vgData, aes(x=Global_Sales)) + geom_boxplot(col='blue') + labs(title= "Figure 2.11:", x= "Global Sales")
```
First, Figure 2.11 shows the box plot for global sales after the missing values were removed. There are now 13,838 different video-games and 36 columns.  There is one outlier which is the total sales for Wii sports. This outlier will not be removed since Wii sports is the most sold Nintendo game with over 82 million copies sold as it came with all Wii consoles. So it is not incorrectly input into the data set. There are still many games with global sales close to 0.1. This is also reasonable for some games that sold less than 10,000 copies. Again since the data was input by users and some of the sales for different platforms were missing the data a lot of the global sales listed are on the low side. For example the video game Minecraft is the most sold video game, however since it's PC sales were not included in the data set, which is its largest platform, the sales for Minecraft are incorrect and they are the tenth most sold on the list. Even with the incorrect data, we will see if we can use the information provided to predict the global sales available. With the data provided the mean of the Global Sales is 0.74 and the standard deviation is 2.20. Predictions will probably end up being on the low side because of this. The only other numeric feature is now year. 



```{r, fig.height = 4, fig.width = 6, fig.align = "center"}
#Plot year versus sales
ggplot(vgData, aes(x=Year, y=Global_Sales)) + geom_point() + labs(title= "Figure 2.12:", x= "Year", y ="Global Sales")
```

Figure 2.12 shows the relationship between Global Sales and Year. The relationship seems to be more quadratic then linear, so for any linear models a transformation will be used by adding a column of $Year^2$ to the features being considered. As years increase it seems so the does the distribution of global sales. However it may be important to consider the fact that games that been released earlier have been on the market for longer.

Next relationship between the categorical columns and Global Sales will be explored. 
 
```{r, fig.height = 20, fig.width = 30, fig.align = "center"}
#Plot a global sales versus a few categorical features
g1=ggplot(vgData, aes(x=Critic_Score,y=Global_Sales)) + geom_boxplot(fill = "white",col = 'black')+labs(title = 'Figure 2.13:', x ='Critic Score', y ='Global Sales')+ theme(text = element_text(size = 30))
g2=ggplot(vgData, aes(x=Developer,y=Global_Sales)) + geom_boxplot(fill = "white",col = 'black')+labs(title = 'Figure 2.14:', x ='Developer', y ='Global Sales')+ theme(text = element_text(size = 30))
g3=ggplot(vgData, aes(x=ESRB_Rating, y = Global_Sales)) + geom_boxplot(fill = "white",col = 'black') + labs(title = 'Figure 2.15:',x = 'ESRB_Rating', y = "Global Sales")+ theme(text = element_text(size = 30))
g4=ggplot(vgData, aes(x=Publisher,y=Global_Sales)) + geom_boxplot(fill = "white",col = 'black')+labs(title = 'Figure 2.16:', x ='Publisher', y ='Global Sales')+ theme(text = element_text(size = 30))
g5=ggplot(vgData, aes(x=Platform_Wii, y = Global_Sales)) + geom_boxplot(fill = "white",col = 'black') + labs(title = 'Figure 2.17:',x = 'Platform Wii')+ theme(text = element_text(size = 30))
g6=ggplot(vgData, aes(x=Genre, y = Global_Sales)) + geom_boxplot(fill = "white",col = 'black') + labs(title = 'Figure 2.18:',x = 'Genre')+ theme(text = element_text(size = 30))

gridExtra::grid.arrange(g1,g2,ncol=1,nrow=2)
```
Figure 2.13 shows the box plot for Critic Score against Global Sales. The Global Sales that seem to be the highest are the review scores that were high.  Figure 2.14 shows that Developer 'Other' had the most sales, this is consistent with the fact that most of the developers were put into the category other. 

```{r, fig.height = 20, fig.width = 40, fig.align = "center"}
#show plots for global sales versus categorical features
gridExtra::grid.arrange(g3,g4, ncol=1,nrow=2)
```

Figure 2.15 shows that the ratings E for Everyone and M for Mature have the highest global sales and EC for early childhood are not as popular. Figure 2.16 shows publishers with the most global sales seem to be Nintendo and Other while Microsoft and Bandai do not have a lot of sales.

```{r, fig.height = 20, fig.width = 30, fig.align = "center"}
#show plots for global sales versus categorical features
gridExtra::grid.arrange(g5,g6, ncol=1,nrow=2)
```
Lastly Figure 2.17 and Figure 2.18 show the relationship for the Platform Wii and Genre against Global Sales.  Most of the platforms generally show the same relationship with global sales, but Wii's have a larger distribution of global sales. The console Wii was one of the most popular Nintendo consoles before the Switch, so this is reasonable. For the category Genre, the genre's with the lowest sales where Educational, Sandbox, and Board game video games. The highest sales are in the categories Action, Misc, and Platform. 


# Section 3: Method 1

## Section 3.1: Introduction

In this section a pruned tree model and random forest model will be used to predict Global Sales. Both will be used to compared to see which model is better at prediction. The pruned tree will be able to show which features are correlated to higher global sales, while the random forest will provide a higher predictive accuracy. Both will be useful to determining the importance of the features. Pruning and random forest will be used to prevent over fitting of the model. 

## Section 3.2: Method
  In order to predict global sales for a video game we will explore a regression tree. This is similar to the classification tree used for imputation. First all the data will be put into a root node with the mean of the global sales, which is 0.7427. It splits the root node into leaves using different features of the data that gives the highest reduction in the training metric which is RSS. RSS is the residual sum of squares which is the square of the difference between the true value of the global sales and the predicted global sales show in the equation below.
  $$RSS = \sum GlobalSales_i - \hat{GlobalSales_i}$$
  The prediction for the global sales of each leaf will be the mean of the global sales that is in the leaf. What feature the tree splits on is dependent on which one gives the highest reduction to the RSS. The trees are grown using recursive binary splitting, meaning it continues the above process adding splits one by one based off the previous split until it stops splitting. Stopping rules can be used to decide when the tree should stop splitting. Some stopping rules are the when the RSS stops decreasing, a max number of splits, or minimum rows allowed in the leaves. This is to prevent the trees from over fitting. The stopping rule that will be used is the tree will not split if the RSS does not decrease by 0.01. This will force the tree to keep splitting until the error stops decreasing by the specified amount. Since all the categories except year are categorical, each categorical feature will be broken into multiple columns, similar to what was done to the  feature platform in Section 2. This is because when creating a tree if the tree splits on a categorical feature with multiple levels it will be hard to interpret. After breaking each categorical feature up there are 88 features in the data set, created by the different levels and there are 13838 different video games in all. This will be used for most of the models as well. 
  
  In order to mitigate over-fitting pruning will be used. Pruning will create a sub tree with fewer leaves built from the full tree. Pruning is removing splits in the original tree to reduce over-fitting. The number of splits will be determined by minimizing RSS + $\alpha |T|$ where T is the number of leaves and $alpha$ is a tuning parameter. The larger $\alpha$ is the less splits the sub tree will have. In order to determine the value of $\alpha$ that is best cross fold validation will be used. Cross validation is when a model is created for different values of $\alpha$ with a subset of the training data and then each model then tested with the rest of the data as validation. This is repeated 10 times with all the data being used as validation data for each value of $\alpha$. Then the value of $\alpha$ that gives the lowest mean square error, which is the RSS divided by the number of rows, for the validation data will be chosen. This creates the sub-tree that is better to use for predicting new data. The pruned tree will show which features predict global sales and which lead to a higher global sales. To calculate the test accuracy, since global sales are numeric, root mean square error, RMSE, will be used to measure how accurate the predictions are. Root mean square error can be calculated by dividing the RSS by the number of rows and taking the square root.
  
  From there a random forest will be created. This is again similar to the method used for imputation where a tree model is created for many samples of the data. The samples will be created using bootstrapping. Bootstrapping is when the original test data is sampled with replacement to create another training data set. For each tree a data set for the video games with the 88 columns and 13838 rows will be created however it will have multiple rows that are exactly the same. Then the bootstrapped video game data will be used to grow a tree.  Instead of using all 88 features to determine each split it will only consider 10 randomly selected features for each split, this is the square root of the number of features. This is so there is more variability in the trees and not only the same splits are being considered each time. The steps of bootstrapping and growing a tree will be repeated 1,000 times. This is because the more samples that are taken then less variability there will be. Once the 1,000 different trees are created with the different bootstrapped samples the test metric will be calculated using the out of bag, OOB, observations. These are predictions that are created using the data that is not included in the respective bootstrap sample. Since each bootstrapped sample may be missing rows from the original data these rows will be used as validation data for the specific tree it is left out of. The prediction for this out of bag observation will be stored. Since a video game can be left out of samples multiple times all out of bag predictions will be averaged to get the final global sale prediction for the game. All the video games final out of bag predictions will be used to calculate the OOB error rate, which is the test RMSE for the tree.
  
  In order to see which features are important for the random forest the importance for each feature will be calculated. The importance is a measure of how often the feature is used and how much it impacts the test RMSE. In order to calculate this the forest calculates how much permuting each feature one at a time affects the OOB error rate if a new forest was created with the permuted feature. The importance is the percent increase in the OOB error rate if the feature was permuted. If any of the features have negative importance they will be removed from the forest to see if the OOB error decreases. Afterwards we will see how the features with the most importance affect the sales price by looking at their partial plots. Partial plots show the relationship of the variable on the predictions the forest makes.
  
## Section 3.3: Results

   The first regression trees uses the root node error to calculate the RMSE for each tree.  The root node error is the mean square error, which is just the RMSE before taking the square root, if all predictions were that the global sales are the mean global sales. The root node error for the data is 4.85, which is an RMSE of 2.201. Meaning if all samples were predicted to have a total sale of 0.7427, which is the mean of the data, then on average the predictions are 2.201 off. This is the same as the standard deviation of the data. Now a tree will be created using 88 features for the video games and using the stopping rule that RMSE must decrease by 0.01. The full tree will have 7 splits. To check that the tree did not over fit pruning will be used.

```{r}
#Create a matrix using the data to turn each categorical column into multiple Boolean columns
X = model.matrix(Global_Sales~., data=vgData)
X = data.frame(X)
X = X[,-1]
X$Global_Sales = vgData$Global_Sales
```

```{r}
#calculate the root node error
n = length(vgData$Global_Sales)
rootMean = mean(vgData$Global_Sales)
relTree1 = (t(vgData$Global_Sales - rootMean) %*% (vgData$Global_Sales - rootMean))/n
```

 

```{r}
library(rpart) 
library(rattle)
library(rpart.plot)
#Grow the full tree using cp=0.01
tree1<- rpart(Global_Sales ~ ., data = X, cp = 0.01, method = "anova")
```
  
  
```{r}
#Show the table for cross validation of the tree
set.seed(27)
knitr::kable(round(tree1$cptable,2), caption = "Tree Cross Validation Results")
```
Table 4 shows the results from cross validation where the 4 column is the percent reduction in the root node error for the validation data. Using cross validation to test the validation accuracy of the tree shows that three splits had the best test accuracy. The test accuracy is 85.7% of the root node error which is a MSE of 4.12 and an RMSE of 2.03. This is not much better than the root node error and is about the same as the standard deviation of the global sales since it means the predictions are about 2,030,000 off from the true global sales on average. 
```{r}
#Grow the tree with 3 splits
tree2<- rpart(Global_Sales ~ ., data = X, cp = tree1$cptable[3,], method = "anova")

#plot the tree
fancyRpartPlot(tree2, sub = "Figure 3.1: Tree with 3 Splits")
```
Figure 3.1 shows the final tree with 3 splits. The tree splits are on if the Critic Score was high, if the publisher was Nintendo, and if the platform was the PS3.  Video games that had a high critic score and were published by Nintendo had the highest predicted global sales which was 4,000,000 million.   Video games with a critic score high not published by Nintendo that were on the PS3 had a predicted total global sales of 3,300,000.  The worst predicted global sales were games that did not have a high critic score.  They were only predicted to have 370,000 global sales. Since the pruned tree did not have a great test RMSE and did not use a lot of the features to split, a random forest will be used instead. 


```{r}
library(randomForest)
#create a random forest using 10 columns
set.seed(27)

#return each row into a factor
for (i in 2:87){
  X[,i] = as.factor(X[,i])
}
rand.GlobalSales <- randomForest(Global_Sales~.,
                  data = X, mtry = 10,
                  importance = TRUE,
                  ntree = 1000,
                  compete= FALSE)
```

```{r}
#Calculated the out of bag RMSE
predict.OOB <- rand.GlobalSales$predicted
n = length(predict.OOB)
residuals = (X$Global_Sales - predict.OOB)
MSE = sum(sort(residuals)^2)/n
RMSErand = sqrt(MSE)
```

After making the random forest the predictive accuracy calculated using the out of bag observations is 1.844. Meaning on average the predictions are 1,844,000 global sales off from the true global sales. This is a lot better than the pruned tree's accuracy.

```{r, fig.height = 10, fig.width = 5, fig.align = "center"}
#Save which features have a positive impact on the forest RMSE
goodfeatures <- which(importance(rand.GlobalSales)[,1] > 0)

#Show a bar chart of the importance
barchart(sort(importance(rand.GlobalSales)[,1][goodfeatures]),
xlab = "Percent Increase in OOB Error",
main = "Figure 3.2: Importance")
```
Figure 3.2 shows the importance for the forest that had a increase in OOB error rate. The features that were not important to the data set where the platforms NES, And, DSIW, 3DS, GEN, and XBL.  As well as the genre action adventure, education, and platform, the publishers Microsoft and Sega, the developer Hudson Soft, and lastly ESRB Rating KA. This is consistent with the box plots shown in Section 2, as many of these features did not have a lot of data and they ended up not being important for the random forest. When these features were permuted they ended up decreasing the OOB error rate, however removing these features and creating a new forest did not improve the test RMSE, so they will be left in the model. The most important features were Genre MMO, Critic Score high, Platform OSX, Critic Score unknown, Platform Nintendo, Year, and Platform PS.  The importance shows that the Platform Nintendo and Critic Score high are important to Global Sales. This is what the tree in 3.1 shows as well. However now the platform PS3 is not as important in predicting global sales. The missing values for Critic Score ended up being important to the model as well. 

```{r, fig.asp=0.5}
#Show partial plots for the two features that were important for both the pruned tree and the random forest
g1=partialPlot(rand.GlobalSales, X,
                x.var = "Critic_Scorehigh",
                xlab = "Critic Score high",
                ylab = "Global Sales",
                main = "Figure 3.3: Critic Score High")
g1=partialPlot(rand.GlobalSales, X,
                x.var = "PublisherNintendo",
                xlab = "Publisher Nintendo",
                ylab = "Global Sales",
                main = "Figure 3.4: Published by Nintendo")
```
Figure 3.3 and 3.4 show the two features that were important to both the tree in Figure 3.1 and the random forest.  The partial plot for the random forest shows that the Publisher Nintendo and Critic Score High lead to a higher predicted global sales similar to the tree. The features Platform PS3, Xbox, and OSX as well as Genre MMO also lead to a higher global sales, but not does not improve the global sales as much as the features in Figure 3.3 and 3.4.

```{r, fig.asp=0.5}

#Show the partial plots for critic score unknown and year
g1=partialPlot(rand.GlobalSales, X,
                x.var = "Critic_ScoreUnknown",
                xlab = "Critic Score Unknown",
                ylab = "Global Sales",
                main = "Figure 3.5: Critic Score Unknown")
g4=partialPlot(rand.GlobalSales, X,
                x.var = "Year",
                xlab = "Year",
                ylab = "Global Sales",
                main = "Figure 3.6: Year")
```
Figure 3.5 shows the partial plot for the missing values of Critic and User Score. It shows that the video games that do not have a score have a lower overall predicted global sales. Figure 3.6 is the partial plot for year. It shows as year increases the global sales decrease. Again this is reasonable since if a game is on the market for longer it will probably have more sales.

# Section 4: Method 2

## Section 4.1: Introduction

In this section best subset selection for least squares linear regression will be used. This is because least squares linear regression is able to do both prediction and association for a numeric response variable. Selection will identify a subset of the features that are best related to global sales and will reduce over fitting my limiting the number of features the model uses. This will also allow the linear model to be easier to interpret. Since only one of the features is numeric not a lot of transformations are required to use a linear model, so it may be better than a tree model since only one transformation, for the feature year, is needed.  This model will provide more information about how global sales is related to other features since the random forest does not give an exact relationship. We will also be able to compare the predictive accuracy of both models and see if they found the same features important to global sales.


## Section 4.2: Method

Least Squares Linear Regression, called LSLR creates a linear model of form:

$$Global Sales = X_D \beta + \epsilon$$
Here $X_D$ is called the design matrix, it is a matrix containing the features of the model, the necessary transformations for the quadratic relationship, which will be $Year^2$, and a column of ones. The matrix $\beta$ represents the coefficients for the linear model and $\epsilon$ is the error term of how far off the predictions are from the true value. Once the model is trained and $\hat{beta}$ is calculated the predictions for global sales will be given by:

$$\hat{Global Sales} = X_D \hat{\beta}$$
In order to find the best features to include, Best Subset Selection (BSS), will be used. This is a technique that determines which features to include. BSS creates a model for different combinations of the features, the first step is with one feature and the intercept, then a model with two features, then three, etc, until a model for each number of features is created. Out of these the one with the best balance of Adjusted R squared and features will be chosen. Adjusted R squared measures how much the features explain the variability of the response data with a penalty for how many features are used. LSLR calculates the $\hat{\beta}$ values that minimize the RSS. Since there are 88 levels in the data it would be computationally expensive to create a model for all possible combinations. Because of this method that will be used is forward step wise selection. Forward step wise selection considers a smaller set of models, it starts with finding the best model with one feature and adding additional features until all features are used, similar to how trees decide on splits dependent on the previous split. The features that will be selected is whichever model has the highest Adjusted $R^2$ without adding too many features to the model. 

Once the features for the model are selected, to calculate the accuracy k-fold cross validation will be used. Again randomly breaking the data into 10 groups and training the model on all but one group and testing on that last group until every group is used as test data. The RMSE for each test set will be calculated and the mean of all 10 RMSE's will be the test RMSE. The final model will be trained on all the data and the coefficients will be shown. Features with positive coefficients will lead to higher predicted global sales while features with a negative coefficient will lead to lower predicted global sales. 

## Section 4.3: Results

```{r}
library(leaps)
set.seed(27)
#run bss for all features with transformations, except ESRB Rating using method forward
bss_sales = regsubsets(Global_Sales~Year+Year^2+Genre+Platform_3DS+Platform_And+Platform_DC+Platform_DS+Platform_DSIW+Platform_GB+Platform_GBA+Platform_GC+Platform_GEN+Platform_NES+Platform_NS+Platform_OSX+Platform_PC+Platform_PS+Platform_PS2+Platform_PS3+Platform_PS4+Platform_PSN+Platform_PSP+Platform_PSV+Platform_SAT+Platform_SNES+Platform_VC+Platform_Wii+Platform_X360+Platform_XB+Platform_XBL+Platform_XOne+Platform_Other+Publisher+Developer+Critic_Score, data=vgData, method="forward",really.big=TRUE)
```

```{r, fig.height = 5, fig.width = 7, fig.align = "center"}
#plot the results of bss_sales
plot(bss_sales,scale="adjr", main= "Figure 4.1:")
```
After adding a column of $year^2$ above shows the results of BSS in Figure 4.1. The best adjusted $R^2$ seems to be with 6 features. After 6 features the adjusted $R^2$ does not increase much more therefore only those 6 features will be used in the model.
```{r}
#Find the features and coefficients for the 6th bss model
suppressMessages(library(knitr))
topTen = which(summary(bss_sales)$which[6,]==TRUE)

#show the coefficients
knitr::kable(coef(bss_sales,6),
    caption = "LSLR Features and Coefficients",
    digits = 2
    )
```
Table 5 shows the 6 best features are year, platform PlayStation 3, Xbox 360, and Xbox One, as well as publisher Nintendo, and Critic Score high. Again Nintendo and Critic Score high are important features as they were for the first model. The final model using the coefficient shown in Table 5 is given by:
$$\begin{aligned}\hat{Global Sales_i} = \\ &  58.71 -0.03Year_i + 0.67PlatformPS3_i +   0.73PlatformX360_i \\ & + 1.49PlatformXOne_i + 1.94PublisherNintendo_i + 1.17CriticScorehigh_i\end{aligned}$$
The coefficient for year is negative meaning as year increases global sales decrease, similar to the forest in Section 3. The decrease is about 3,000 sales for each year. Games that are published by Nintendo have an increase of 1,940,000 predicted global sales. Similarly, having a Critic Score high increases predicted sales by 1,170,000 and platform Xbox One increases it 1,490,000. Lastly the platforms PlayStation 3 and Xbox 360 increase sales by 670,000 and 730,000 respectively.

```{r}
set.seed(27)
#Run 10 fold cross validation for the BSS model  
storage <- data.frame("K" = rep(NA,10),'RMSE'=rep(NA,10)) 
n <- nrow(vgData)
  
pool <- rep(1:10,ceiling(n/10))
folds <- sample(pool,n)
    
#loop for 10 f
for (f in 1:10){
  storage$K[f]=f
    
  infolds <- which(folds == f)
    
  newTrain <- X[-infolds,]
  newTest<-X[infolds,] #breaks up data into training and test by row
  m = length(newTest)
  
  #create the model with the training data
  lmFold = lm(Global_Sales~Year+Platform_PS31+Platform_X3601+Platform_XOne1+PublisherNintendo+Critic_Scorehigh, data=newTrain)
  
  #create the predictions using the test data
  predictions = predict(lmFold,newTest)
  
  #save the result
  storage$RMSE[f] = sqrt(t(predictions - newTest$Global_Sales)%*%(predictions - newTest$Global_Sales)/n)
    
    #Store ith RMSE in the data frame
  }
```


```{r}
#Calculate the RMSE of the LSLR Model
LSLRRMSE = mean(storage$RMSE)
```

After using 10 fold cross validation to evaluate the model with the 6 features the test RMSE is 0.62. This means on average the predictions are about 62,000 sales off which is a 66% percent decrease in test RMSE when compared to the random forest test RMSE in section 3.

```{r}
#create the final model using all the training data
lmFinal = lm(Global_Sales~Year+Platform_PS31+Platform_X3601+Platform_XOne1+PublisherNintendo+Critic_Scorehigh, data=X)
```

# Section 5: Method 3

## Section 5.1: Introduction

The last model that will be used is called Elastic Net. This method is usually used when there is correlation between features. This is good since ESRB could not be used for least squares linear regression as it was dependent on the other features. Elastic net is another type of linear model that preforms both selection and prediction, but instead of minimizing the RSS it penalties the RSS plus a shrinkage term. This allows the model to penalize for large values of $\beta$ so that the variance of the estimation is lower and since the $\beta$ terms can be shrunk to zero with Elastic Net it is able to preform selection. Elastic net will also be different from the model in method 1 and 2 since it will consider more features like the random forest while still providing more information about the relationship between features like LSLR. Then we will be able to see if the same features ended up being important and compare the test RMSE for all three models. 

## Section 5.2: Method

Elastic net is a shrinkage technique that shrinks the coefficients to zero by using a shrinkage penalty which lowers the variance in the estimation. This model minimizes the RSS plus the shrinkage penalty which utilizes the sum of square $\hat{\beta}$ and sum of absolute value of the $\hat{\beta}$ below:


$$RSS + \lambda\sum[(1-\alpha)\hat{\beta}^2+\alpha |\hat{\beta}|]$$
This allows the coefficients to be shrunken to zero, picking the best coefficients for the model. The tuning parameters are $\lambda$ and $\alpha$. $\alpha$ represents the percent of each shrinkage penalty the model uses. Then it shrinks the value the RSS plus the two shrinkage penalties. The tuning parameter $\lambda$ is a number used to adjust the penalty. To choose the tuning parameter cross validation will be used. Cross validation creates a model for each value of $\lambda$ and $\alpha$ at the same time by creating a model for all combinations. $\lambda$ will consider all values from 0 to 1000 at a step size of 0.5. If 0 is the best value of $\lambda$ the model will be LSLR and the larger the value of $\lambda$ the larger the penalty for large $\beta$ values. The values for $\alpha$ that will be considered are $\alpha$ between 0 and 1 increasing at steps of .05. Then while different values of $\lambda$ and $\alpha$ are being tested the model also does 10-fold cross validation to test each model, taking a portion of the training data and using it to test each model and calculate the test RMSE repeating with 10 different portions of the data. The $\lambda$ and $\alpha$ that is chosen is the one with the smallest test RMSE. This balances the bias and the variance of the predictions. The model matrix will be the same as the matrix from LSLR which includes the transformations for years.

Once the final model is chosen it will be trained with all the data and the coefficients will be shown from largest to smallest. The largest most positive value of the coefficients will be the feature that increases global sales the most and the most negative will decrease the global sales the most.




## Section 5.3: Results

```{r}
suppressMessages(library(caret))
suppressMessages(library(glmnet))

#Set a random seed
set.seed(27)

Xlm = vgData
Xlm$year2 = (X$Year)^2

#Create the model matrix
XD <- model.matrix(Global_Sales ~ ., data = Xlm)
XD = data.frame(XD)
XD = XD
XD$Global_Sales =vgData$Global_Sales

#Values of alpha and lambda to test
tuningGrid <- data.frame("alpha" = seq(from = 0, to = 1, by = .05), "lambda"= seq(from =0, to =5, by =.25))

set.seed(27)

#Preform cross validation for elastic net
globalSales_elnet = train(
  Global_Sales ~ ., data = XD,
  method = "glmnet",
  tuneGrid = tuningGrid,
  trControl = trainControl(method = "cv", number = 10)
)

#Find the lowest RMSE
location = which(globalSales_elnet$results$RMSE==min(globalSales_elnet$results$RMSE))
ElasticRMSE = globalSales_elnet$results[location,3] 
suppressMessages(knitr::kable(round(globalSales_elnet$results[location,1:3],2),caption = "Tuning Parameters for Best Test RMSE"))
```

Table 6 shows the results of cross validation with the different values of $\lambda$ and $\alpha$. The values that are shown are the values that gave the lowest test RMSE. Since $\lambda$ = 0 was chosen this means the most is the same as a least square linear regression since now to get the coefficients it is only minimizing RSS without any penalty. The test RMSE calculated from 10 fold cross validation is 1.94, so the predictions ar about 1,940,000 sales off on average.

```{r}
#Create the elastic net model with lambda 0 and alpha=0 and find the coefficients
ridgeFinal <- glmnet(XD[,-c(1,90)],XD$Global_Sales,alpha=0,lambda=0)
Betas <- as.numeric(coef(ridgeFinal))
rowNames <- colnames(XD[,-90])
BetasFinal <- data.frame("Column Names" = rowNames, "Coefficients" = round(Betas,2))
knitr::kable(BetasFinal[order(BetasFinal$Coefficients),],
    caption = "Elastic Net Features and Coefficients")
```
Table 7 above shows the coefficients for the model.  The model uses all features, except one, so there are 88 $\hat{\beta}$ values in all. The only feature that was removed from the model is ESRB Rating KA, since it has a coefficient of 0, the other coefficients that were close to zero like for $Year^2$ were rounded up. The KA rating also had negative important in the Random Forest. The features with the largest positive coefficients, besides the intercept are the platforms And and Xbox One, publisher Nintendo, critic score high, and genre MMO. This is similar to the results from the first and second model. The forest in model 1 found the platform And was not important, but with elastic net it shows that the platform And leads to a higher global sales by about 1,519,000 sales. Nintendo increases the sales by 1,490,138. The features that lead to a lower Global Sales are any publisher that is not EA sports or Nintendo, in fact 11 out of the 16 platforms have 11 out of 12 the most negative coefficients. The coefficients for these platforms are between -0.86 and -0.43. Therefore if the video game was published by one of these 11 publishers the predicted global sales decrease anywhere from 452,561 to 860,876. Platform DSIW also has a negative coefficient of 0.85. The feature Year, which was used in the forest and LSLR has a coefficient of -0.01 and -0.0000000031 for $Year^2$. Since the earliest year is 1970 these small coefficients still have an affect on global sales. So again the newer the game the lower the predicted global sales.  Interestingly, the missing critic scores have a positive coefficient in this model of 0.013, the only critic score that does not increase the predicted global sales is an average score. 


# Section 6: Conclusions

\begin{table}[ht]
\centering
\caption {RMSE of All Regression Models} \label{tab:} 
\begin{tabular}{rl}
  \hline
 Model.Name & RMSE \\ 
  \hline
 LSLR & 0.62 \\ 
 Elastic Net & 1.94 \\ 
 Regression Tree & 2.03 \\ 
 Random Forest & 1.84 \\ 
   \hline
\end{tabular}
\end{table}

Table 8 shows the test RMSE for each model. It shows the best model was LSLR using best subset selection with 6 features. It had the lowest test RMSE of 0.62. The second best model was the random forest. The features that lead to the highest predicted global sales for all the models were the publisher Nintendo and games that had a higher critic and user score. The features that lead to a lower predicted global sales were the year the game was released for every model except Elastic Net.

```{r}
#Prepare the test data by turning it into a matrix with each categorical columns turned into Boolean
vgTest$Global_Sales = 0
XTest = model.matrix(Global_Sales~.,vgTest)
XTest = data.frame(XTest)

#remove the column of ones that was added
XTest = XTest[,-1]
XTest$Global_Sales = vgTest$Global_Sales

#create the predictions using the pruned tree
tree_preds = predict(tree2,XTest)

#turn the columns into factors if they are not numeric
for (i in 2:87){
  XTest[,i] = factor(XTest[,i], levels = levels(X[,i]))
}

#create the predictions for the test data using the random forest
randforest_preds = predict(rand.GlobalSales,XTest)

#apply the transformation to year for the linear models
XTest$year2 = XTest$Year^2
XTest$Global_Sales = 0
Betas = data.frame(Betas)

#create the predictions using the final LSLR model
lm_preds = predict(lmFinal,XTest)

#Create the predictions using the final elastic net model
XTestnew = model.matrix(Global_Sales~.,vgTest)
XTestnew = data.frame(XTestnew)
XTestnew$year2 = XTestnew$Year^2
elastic_preds = data.matrix(XTestnew)%*%data.matrix(Betas)

```



To get a better idea of how the models are predicting global sales differently they will be used to predict the global sales for the data that was removed during Section 2.

```{r,fig.asp=0.7}
#Plot the predictions for each model against year
g1 = ggplot(data=XTest, aes(x=Year, y = tree_preds)) + geom_point(col = 'green')+ labs(title = "Figure 6.1:",x = "Year", y="Tree Predictions")
g2 = ggplot(data=XTest, aes(x=Year, y = randforest_preds)) + geom_point(col='purple')+ labs(title = "Figure 6.2:",x = "Year", y="Random Forest Predictions")
g3 = ggplot(data=XTest, aes(x=Year, y=elastic_preds)) + geom_point(col='red')+ labs(title = "Figure 6.3:",x = "Year", y="Elastic Net Predictions")
g4 = ggplot(data=XTest, aes(x=Year, y = lm_preds)) + geom_point(col='blue')+ labs(title = "Figure 6.4:",x = "Year", y="Least Squares Prediction")
gridExtra::grid.arrange(g1,g2,g3,g4, ncol=2,nrow=2)
```

Figure 6.1-6.4 show the predictions for global sales for each model plotted against year. Figure 6.1 shows the Tree predictions for the tree. Since the tree only had four leaves there are only 4 different predictions for the video game global sales. Figure 6.2 shows the Random Forest predictions, which seems to keep the same relationship with year that the training data had.  Figure 6.3 shows the Elastic Net predictions and Figure 6.4 shows the least squares linear regression predictions. In Figure 6.2 and 6.4 some of the predictions are less than zero, while in figure 6.3 a lot of the global sales predictions are less than zero. This is not reasonable since a game cannot sell negative copies. To get a better idea of the predictions we will look at all four models predictions on the same plot. 

```{r, fig.asp=0.5}
#show the plots for all 3 final models on one plot against year
suppressMessages(ggplot(XTest, aes(x = Year)) + 
  geom_point(aes(y = tree_preds), color = "green") + 
  geom_point(aes(y = randforest_preds), color = "purple") + 
  geom_point(aes(y = elastic_preds), color = "red") + 
  geom_point(aes(y = lm_preds), color = "blue") + labs(title = "Figure 6.5:",x = "Year", y="Global Sales Predictions"))
```
Figure 6.5 shows the distribution of the predictions for the test data for each model. They all seem to have the same distribution, while it seems the Elastic Net predictions (red) are under estimating while the Random Forest predictions (purple) are over estimating. The least squares linear regression predictions (blue) seem to be in the middle of the two. To look at if the predictions for games are similar we will look at the top predicted global sales for the models for Random Forest, Elastic Net, and LSLR for both the test and training data.


```{r}
#create the predictions for the training data
randforest_preds_train = predict(rand.GlobalSales,X)
lm_preds_train = lmFinal$fitted
elastic_preds_train = data.matrix(XD[,-90])%*%data.matrix(Betas)

```

```{r}
#find the test and training video game that each model predicted to have the highest global sales

largestLMTest = which(lm_preds == max(lm_preds))
largestENTest = which(elastic_preds == max(elastic_preds))
largestRFTest = which(randforest_preds == max(randforest_preds))

largestLM = which(lm_preds_train == max(lm_preds_train))
largestEN = which(elastic_preds_train == max(elastic_preds_train))
largestRF = which(randforest_preds_train == max(randforest_preds_train))

#show the predictions
mostPredictedSales = data.frame("Model" =c("Random Forest", "Elastic Net","LSLR"), "Training Title" = c(titles[largestRF][1],titles[largestEN][1],titles[largestRF][1]),"Test Title" = c(titlesTest[largestRFTest][1],titlesTest[largestENTest][1],titlesTest[largestLMTest][1]))
knitr::kable(mostPredictedSales, caption = "Video Game with Highest Predicted Global Sales")

```
Table 9 shows the predicted game with the highest global sales price for all three final models. All three models predicted a different game to have the highest global sales in the test data. Both LSLR and Random Forest both predicted Wii Sports to have the highest global sales in the training data. This is correct since in Section 2 it was shown to be the highest sold video game on the list. The Random Forest predicted it to have 23.68 global sales while LSLR predicted it to have 4.57 global sales, however it's true value is 82.86 global sales. Therefore the predictions for each model seem to be underestimating the video games with higher global sales because most of the data was already on the low side. One solution to the short comings of the models is instead to pick a threshold for global sales and explore whether or not the sales for a video-game were above or below that threshold. Looking at global sales as a category may allow the models to pick up on features related to even higher sales prices.

Since the goal was prediction and association for global sales as a numeric feature, in all the best model for both prediction and association was the least squares regression model with six features. This is because it had the lowest test RMSE and was the easiest to interpret to learn which features were able to predict sales price. However, while all the models underestimate sales, the random forest model underestimates the least for the video games that did have higher sales, so if you only want to predict games with higher sales the random forest may be better. 

\newpage

# Works Cited Page

[1]  Sales Of Video Games, Retrieved April 27, 2022 from https://www.kaggle.com/datasets/arslanali4343/sales-of-video-games

[2]  Video_Games_Sales_2019. Retrieved April 7, 2022 from https://www.kaggle.com/datasets/janoslaszlo/video-games-sales-2019
